---
phase: 02-pr-metrics
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - scripts/ado-client.mjs
  - scripts/pr-metrics.mjs
autonomous: true
requirements: [PR-01, PR-02, PR-03, PR-04, PR-05]

must_haves:
  truths:
    - "Running `node scripts/pr-metrics.mjs` outputs valid JSON with all required metric fields"
    - "Cycle time (PR-02) is computed only from completed PRs using closedDate - creationDate"
    - "Time-to-first-review (PR-01) is derived from VoteUpdate thread events, not the reviewers array"
    - "Stale PR detection (PR-04) uses max thread lastUpdatedDate as last activity, not creationDate"
    - "Reviewer distribution (PR-03) excludes self-reviews and zero-vote reviewers"
    - "Bottleneck detection (PR-05) identifies the reviewer with highest avg time-to-first-review"
    - "Thread fetches are batched in groups of 10 via Promise.allSettled to avoid rate limits"
    - "Fallback strategy: all-time → 365 days → 90 days when PR count is large"
  artifacts:
    - path: "scripts/ado-client.mjs"
      provides: "PR API fetch functions: adoGetPrsByProject, adoGetPrsByRepo, adoGetPrThreads, adoGetRepos"
      contains: "adoGetPrsByProject"
    - path: "scripts/pr-metrics.mjs"
      provides: "Full PR metrics computation script — outputs structured JSON to stdout"
      exports: []
      contains: "findFirstReviewDate"
      min_lines: 150
  key_links:
    - from: "scripts/pr-metrics.mjs"
      to: "scripts/ado-client.mjs"
      via: "ESM import"
      pattern: "import.*ado-client"
    - from: "scripts/pr-metrics.mjs"
      to: "scripts/config.mjs"
      via: "ESM import of loadConfig"
      pattern: "import.*config"
    - from: "scripts/pr-metrics.mjs"
      to: "stdout JSON"
      via: "console.log(JSON.stringify(...))"
      pattern: "JSON\\.stringify"
---

<objective>
Extend the ADO client with PR-specific fetch functions and build the pr-metrics.mjs computation script that fetches pull request data from Azure DevOps, computes all required metrics, and outputs structured JSON for Claude to narrate.

Purpose: This is the data and computation layer. The skill (Plan 02) depends on this JSON contract being well-defined and deterministic. All metric math lives here — not in Claude's narrative pass.

Output:
- `scripts/ado-client.mjs` extended with 4 new functions: adoGetPrsByProject, adoGetPrsByRepo, adoGetPrThreads, adoGetRepos
- `scripts/pr-metrics.mjs` — complete computation script outputting the defined JSON schema
</objective>

<execution_context>
@C:/Users/7N_TSM/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/7N_TSM/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-pr-metrics/02-RESEARCH.md
@.planning/phases/01-foundation/01-02-SUMMARY.md
@scripts/ado-client.mjs
@scripts/config.mjs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend ado-client.mjs with PR API fetch functions</name>
  <files>scripts/ado-client.mjs</files>
  <action>
Add 4 new exported async functions to the BOTTOM of scripts/ado-client.mjs (do not modify existing functions):

**1. adoGetPrsByProject(config, params = {})**
Fetches PRs across all repos in the project using the project-wide endpoint.
- URL: `{config.orgUrl}/{config.project}/_apis/git/pullrequests`
- Always set `api-version=7.1`
- Merge all `params` entries into URL search params (skip null/undefined values)
- Use `buildAuthHeader(config.pat)` for Authorization header
- Throw typed error on non-ok response: `Object.assign(new Error('PR fetch failed: ' + status), { type: 'api', status })`
- Return `response.json()` — shape: `{ value: GitPullRequest[], count: number }`

**2. adoGetPrsByRepo(config, repoId, params = {})**
Fetches PRs for a single repository (used when --repo flag is specified).
- URL: `{config.orgUrl}/{config.project}/_apis/git/repositories/{repoId}/pullrequests`
- Same auth, params merging, error handling as adoGetPrsByProject
- Return `response.json()` — same shape

**3. adoGetPrThreads(config, repoId, prId)**
Fetches the thread list for a single PR (used for time-to-first-review and staleness).
- URL: `{config.orgUrl}/{config.project}/_apis/git/repositories/{repoId}/pullRequests/{prId}/threads`
- Set `api-version=7.1`
- Use `buildAuthHeader(config.pat)`
- On non-ok response: return `{ value: [] }` (tolerate single PR failure — do not throw)
- Return `response.json()` — shape: `{ value: GitPullRequestCommentThread[] }`

**4. adoGetRepos(config)**
Lists all repositories in the project (used to resolve repo name → ID for --repo flag).
- URL: `{config.orgUrl}/{config.project}/_apis/git/repositories`
- Set `api-version=7.1`
- Use `buildAuthHeader(config.pat)`
- Throw typed error on non-ok response
- Return `response.json()` — shape: `{ value: GitRepository[] }`

All new functions must use only built-in Node.js APIs (native fetch, no npm packages). Follow the exact coding style of the existing adoGet function in ado-client.mjs.
  </action>
  <verify>
    <automated>node -e "
import('./scripts/ado-client.mjs').then(m => {
  const missing = ['adoGetPrsByProject','adoGetPrsByRepo','adoGetPrThreads','adoGetRepos'].filter(fn => typeof m[fn] !== 'function');
  if (missing.length) { console.error('MISSING:', missing.join(', ')); process.exit(1); }
  console.log('OK: all 4 PR fetch functions exported');
}).catch(e => { console.error(e.message); process.exit(1); })
"</automated>
    <manual>Inspect scripts/ado-client.mjs — 4 new functions appended at bottom, existing functions unchanged</manual>
  </verify>
  <done>ado-client.mjs exports adoGetPrsByProject, adoGetPrsByRepo, adoGetPrThreads, adoGetRepos alongside all existing Phase 1 exports (adoGet, validateConnection, buildAuthHeader)</done>
</task>

<task type="auto">
  <name>Task 2: Create pr-metrics.mjs — full data fetch and computation script</name>
  <files>scripts/pr-metrics.mjs</files>
  <action>
Create `scripts/pr-metrics.mjs` as a complete Node.js ESM script. It imports from ado-client.mjs and config.mjs, fetches PR data, computes all metrics, and outputs a single JSON object to stdout. No human-readable strings in stdout — only JSON.

**Arg parsing** (follow setup.mjs pattern exactly):
```javascript
const args = Object.fromEntries(
  process.argv.slice(2)
    .filter(a => a.startsWith('--'))
    .map(a => { const eq = a.indexOf('='); return eq > 0 ? [a.slice(2, eq), a.slice(eq + 1)] : [a.slice(2), 'true']; })
);
const repoFilter = args.repo || null;
const daysOverride = args.days ? parseInt(args.days, 10) : null;
const staleDays = args['stale-days'] ? parseInt(args['stale-days'], 10) : 3;
const projectOverride = args.project || null;
const checkConfig = args['check-config'] === 'true';
```

**Config check mode** (for SKILL.md Step 0 guard):
If `checkConfig` is true: load config, if missing output `{"configMissing": true}` and exit 0. If exists, output `{"configMissing": false}` and exit 0.

**Config loading**: Use `loadConfig()` from config.mjs. Apply `projectOverride` if set: `config.project = projectOverride`.

**Main flow** — wrap everything in a top-level try/catch; on any uncaught error output `{"error": {"type": "unexpected", "message": e.message}}` and exit 1.

**PR Fetch with fallback strategy**:
```
windows = daysOverride ? [daysOverride] : [null, 365, 90]
for each window:
  minTime = window ? new Date(Date.now() - window * 86400000).toISOString() : null
  fetch all pages with $skip/$top=1000 pagination
  if no daysOverride AND prs.length >= 500: continue to next (shorter) window
  else: use this result
cap total $skip pages at 10 (10,000 PRs max); if cap hit, add note to output
```

If `repoFilter` is set: use adoGetRepos to find matching repo by name (case-insensitive). If not found, output `{"error": {"type": "not_found", "message": "Repository '<name>' not found.", "availableRepos": [list]}}` and exit 1. Then use adoGetPrsByRepo instead of adoGetPrsByProject.

Always pass `searchCriteria.status=all` — NEVER omit this (pitfall: defaults to active-only).

**Thread fetching** — only fetch threads for PRs where needed:
- Active PRs: need threads for staleness detection (last activity date) and time-to-first-review for pending PRs
- Completed PRs: need threads only for time-to-first-review (for merged PRs without a first-review timestamp already computed)
- Batch 10 at a time using Promise.allSettled
- On HTTP 429: retry that batch once after 2 seconds
- Collect thread fetch results into a Map: `prId → threads.value`

**Computation functions** (implement as named functions, not lambdas):

`findFirstReviewDate(threads, prCreatorId)`:
- Filter threads where `t.properties?.CodeReviewThreadType?.$value === 'VoteUpdate'`
- AND `t.comments?.[0]?.author?.id !== prCreatorId`
- If none: return null
- Return `new Date(earliest.publishedDate)` (reduce by publishedDate)

`getLastActivityDate(pr, threads)`:
- Map all threads to `new Date(t.lastUpdatedDate)`, filter valid dates
- If no threads: return `new Date(pr.creationDate)`
- Return `new Date(Math.max(...dates.map(d => d.getTime())))`

`isStale(pr, threads, staleDaysThreshold)`:
- Only for `pr.status === 'active'`
- Return `(Date.now() - getLastActivityDate(pr, threads).getTime()) / 86400000 > staleDaysThreshold`

**Reviewer distribution**:
- For each PR, for each reviewer in `pr.reviewers`:
  - Skip if `reviewer.id === pr.createdBy.id` (self-review, pitfall 4)
  - Skip if `reviewer.vote === 0` (added but not acted, pitfall per research)
  - Skip if `reviewer.isContainer === true` (team reviewer, not individual)
  - Accumulate per-reviewer: reviewCount, array of firstReviewTimeHours
- For time per reviewer: use per-PR thread data. For each PR where a reviewer voted non-zero, find the VoteUpdate thread for THAT reviewer specifically: `t.comments?.[0]?.author?.id === reviewer.id` — the earliest such thread gives their personal first-review time for that PR
- Output sorted descending by reviewCount

**Absent reviewers** (PR-03):
- Collect all unique PR creator IDs and display names
- Collect all IDs who appear as active reviewer (non-zero vote, non-self) on any PR
- `absentReviewers` = PR creators whose ID never appears in the active reviewer set

**Bottleneck** (PR-05):
- Among reviewers with at least 3 reviews (to avoid outlier noise), find the one with highest `avgTimeToReviewHours`
- Also detect concentration: if reviewer.reviewCount / totalNonZeroVotes > 0.5, flag as concentration bottleneck
- If both apply, use whichever is more severe (slowest reviewer who also has concentration)
- Output: `{ name, avgTimeToReviewHours, reviewShare, type: 'slow'|'concentrated'|'both' }`
- If no bottleneck candidate (all reviewers < 3 reviews): null

**JSON output schema** (output via `console.log(JSON.stringify(result))`):
```json
{
  "summary": {
    "totalPrs": N,
    "activePrs": N,
    "completedPrs": N,
    "reposAnalyzed": N,
    "repoNames": [...],
    "daysCovered": N_or_null,
    "fetchedAt": "ISO timestamp",
    "capHit": false
  },
  "cycleTimes": {
    "meanHours": N_or_null,
    "medianHours": N_or_null,
    "unit": "hours",
    "prCount": N
  },
  "timeToFirstReview": {
    "meanHours": N_or_null,
    "medianHours": N_or_null,
    "unit": "hours",
    "prCount": N,
    "missingCount": N,
    "aboveThresholdCount": N,
    "healthyThresholdHours": 4
  },
  "reviewerDistribution": [
    { "name": "...", "reviewCount": N, "avgTimeToReviewHours": N_or_null }
  ],
  "absentReviewers": ["name", ...],
  "stalePrs": [
    { "title": "...", "repo": "...", "daysStale": N, "createdBy": "...", "url": "..." }
  ],
  "bottleneck": { "name": "...", "avgTimeToReviewHours": N, "reviewShare": N, "type": "..." } | null,
  "thresholds": {
    "staleThresholdDays": N,
    "healthyReviewHours": 4
  },
  "errors": ["repo/PR level error messages if any"]
}
```

Cycle time guard — only for `status === 'completed'` AND `pr.closedDate` exists (pitfall 5).
Never include abandoned PRs in cycle time: only `status === 'completed'` (pitfall: closedDate is set for abandoned too).

**Progress output to stderr** (not stdout, to avoid polluting JSON):
`process.stderr.write('Fetching PRs...\n')` during the fetch phase.
  </action>
  <verify>
    <automated>node -e "
// Test: script runs in check-config mode without a real ADO connection
import('./scripts/pr-metrics.mjs').then(() => {
  console.log('IMPORT OK');
}).catch(e => {
  // Expected to fail at runtime (no config), but import should succeed
  if (e.message && e.message.includes('SyntaxError')) { console.error('SYNTAX ERROR:', e.message); process.exit(1); }
  console.log('OK: module syntax valid (runtime error expected without config)');
});
" 2>/dev/null; node --input-type=module --eval "
import { createRequire } from 'module';
import { readFileSync } from 'fs';
const src = readFileSync('./scripts/pr-metrics.mjs', 'utf8');
const checks = [
  ['arg parsing', src.includes('process.argv')],
  ['check-config mode', src.includes('checkConfig')],
  ['searchCriteria.status=all', src.includes('searchCriteria.status')],
  ['findFirstReviewDate', src.includes('findFirstReviewDate')],
  ['VoteUpdate', src.includes('VoteUpdate')],
  ['getLastActivityDate', src.includes('getLastActivityDate')],
  ['isStale', src.includes('isStale')],
  ['Promise.allSettled', src.includes('allSettled')],
  ['JSON.stringify output', src.includes('JSON.stringify')],
  ['self-review exclusion', src.includes('createdBy.id')],
  ['zero-vote exclusion', src.includes('vote === 0')],
  ['cycle time guard', src.includes('closedDate')],
  ['status=completed guard', src.includes(\"status === 'completed'\")],
  ['stderr progress', src.includes('stderr')],
  ['import ado-client', src.includes('ado-client')],
  ['import config', src.includes('config.mjs')],
];
const failed = checks.filter(([,ok]) => !ok).map(([name]) => name);
if (failed.length) { console.error('MISSING IMPLEMENTATIONS:', failed.join(', ')); process.exit(1); }
console.log('OK: all required implementations present (' + checks.length + ' checks)');
" 2>/dev/null</automated>
    <manual>Review pr-metrics.mjs — confirm JSON output schema matches the defined contract; confirm no human-readable strings in stdout paths</manual>
  </verify>
  <done>
    - scripts/pr-metrics.mjs exists with all required computation functions
    - Outputs JSON matching the defined schema (all 8 top-level keys present)
    - All 6 anti-patterns from RESEARCH.md are avoided (searchCriteria.status=all, closedDate guard, vote=0 exclusion, self-review exclusion, completed-only cycle time, thread batching)
    - --check-config mode works without network access
  </done>
</task>

</tasks>

<verification>
After both tasks complete:
1. `node -e "import('./scripts/ado-client.mjs').then(m => console.log(Object.keys(m).join(', ')))"` — must show adoGet, validateConnection, buildAuthHeader, adoGetPrsByProject, adoGetPrsByRepo, adoGetPrThreads, adoGetRepos
2. `node --input-type=module --eval "import {readFileSync} from 'fs'; const s=readFileSync('./scripts/pr-metrics.mjs','utf8'); console.log(s.length + ' chars, ' + s.split('\n').length + ' lines')"` — must be 150+ lines
3. `node scripts/pr-metrics.mjs --check-config 2>/dev/null` — must output valid JSON (either `{"configMissing":true}` or `{"configMissing":false}`)
</verification>

<success_criteria>
- adoGetPrsByProject, adoGetPrsByRepo, adoGetPrThreads, adoGetRepos all exported from ado-client.mjs
- pr-metrics.mjs handles all computation for PR-01 through PR-05
- JSON output schema is complete and matches the contract the SKILL.md will reference
- All research pitfalls avoided (confirmed by verify checks)
- Zero new npm dependencies introduced
</success_criteria>

<output>
After completion, create `.planning/phases/02-pr-metrics/02-01-SUMMARY.md`
</output>
